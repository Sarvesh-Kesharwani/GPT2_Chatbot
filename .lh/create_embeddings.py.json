{
    "sourceFile": "create_embeddings.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1731340138099,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1731340177608,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,29 +1,71 @@\n+# from langchain.document_loaders import DirectoryLoader\r\n+from langchain_community.document_loaders import DirectoryLoader\r\n+from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n+from langchain.schema import Document\r\n+# from langchain.embeddings import OpenAIEmbeddings\r\n from langchain_openai import OpenAIEmbeddings\r\n-from langchain.evaluation import load_evaluator\r\n+from langchain_community.vectorstores import Chroma\r\n+import openai \r\n from dotenv import load_dotenv\r\n-import openai\r\n import os\r\n+import shutil\r\n \r\n # Load environment variables. Assumes that project contains .env file with API keys\r\n load_dotenv()\r\n #---- Set OpenAI API key \r\n # Change environment variable name from \"OPENAI_API_KEY\" to the name given in \r\n # your .env file.\r\n openai.api_key = os.environ['OPENAI_API_KEY']\r\n \r\n+CHROMA_PATH = \"chroma\"\r\n+DATA_PATH = \"data/books\"\r\n+\r\n+\r\n def main():\r\n-    # Get embedding for a word.\r\n-    embedding_function = OpenAIEmbeddings()\r\n-    vector = embedding_function.embed_query(\"apple\")\r\n-    print(f\"Vector for 'apple': {vector}\")\r\n-    print(f\"Vector length: {len(vector)}\")\r\n+    generate_data_store()\r\n \r\n-    # Compare vector of two words\r\n-    evaluator = load_evaluator(\"pairwise_embedding_distance\")\r\n-    words = (\"apple\", \"iphone\")\r\n-    x = evaluator.evaluate_string_pairs(prediction=words[0], prediction_b=words[1])\r\n-    print(f\"Comparing ({words[0]}, {words[1]}): {x}\")\r\n \r\n+def generate_data_store():\r\n+    documents = load_documents()\r\n+    chunks = split_text(documents)\r\n+    save_to_chroma(chunks)\r\n \r\n+\r\n+def load_documents():\r\n+    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\r\n+    documents = loader.load()\r\n+    return documents\r\n+\r\n+\r\n+def split_text(documents: list[Document]):\r\n+    text_splitter = RecursiveCharacterTextSplitter(\r\n+        chunk_size=300,\r\n+        chunk_overlap=100,\r\n+        length_function=len,\r\n+        add_start_index=True,\r\n+    )\r\n+    chunks = text_splitter.split_documents(documents)\r\n+    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\r\n+\r\n+    document = chunks[10]\r\n+    print(document.page_content)\r\n+    print(document.metadata)\r\n+\r\n+    return chunks\r\n+\r\n+\r\n+def save_to_chroma(chunks: list[Document]):\r\n+    # Clear out the database first.\r\n+    if os.path.exists(CHROMA_PATH):\r\n+        shutil.rmtree(CHROMA_PATH)\r\n+\r\n+    # Create a new DB from the documents.\r\n+    db = Chroma.from_documents(\r\n+        chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\r\n+    )\r\n+    db.persist()\r\n+    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\r\n+\r\n+\r\n if __name__ == \"__main__\":\r\n     main()\n\\ No newline at end of file\n"
                }
            ],
            "date": 1731340138099,
            "name": "Commit-0",
            "content": "from langchain_openai import OpenAIEmbeddings\r\nfrom langchain.evaluation import load_evaluator\r\nfrom dotenv import load_dotenv\r\nimport openai\r\nimport os\r\n\r\n# Load environment variables. Assumes that project contains .env file with API keys\r\nload_dotenv()\r\n#---- Set OpenAI API key \r\n# Change environment variable name from \"OPENAI_API_KEY\" to the name given in \r\n# your .env file.\r\nopenai.api_key = os.environ['OPENAI_API_KEY']\r\n\r\ndef main():\r\n    # Get embedding for a word.\r\n    embedding_function = OpenAIEmbeddings()\r\n    vector = embedding_function.embed_query(\"apple\")\r\n    print(f\"Vector for 'apple': {vector}\")\r\n    print(f\"Vector length: {len(vector)}\")\r\n\r\n    # Compare vector of two words\r\n    evaluator = load_evaluator(\"pairwise_embedding_distance\")\r\n    words = (\"apple\", \"iphone\")\r\n    x = evaluator.evaluate_string_pairs(prediction=words[0], prediction_b=words[1])\r\n    print(f\"Comparing ({words[0]}, {words[1]}): {x}\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()"
        }
    ]
}